{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pandas.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CB3Wyg2n1xgF"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pandas"
      ],
      "metadata": {
        "id": "Te36XGTr1zF3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pandas is a Python library.\n",
        "\n",
        "Pandas is used to analyze data.\n",
        "What is Pandas?\n",
        "Pandas is a Python library used for working with data sets.\n",
        "\n",
        "It has functions for analyzing, cleaning, exploring, and manipulating data.\n",
        "Pandas allows us to analyze big data and make conclusions based on statistical theories.\n",
        "\n",
        "Pandas can clean messy data sets, and make them readable and relevant.\n",
        "\n",
        "Relevant data is very important in data science."
      ],
      "metadata": {
        "id": "SlKTnk0SCegd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Pandas\n",
        "import pandas\n",
        "#Create an alias with the as keyword while importing.\n",
        "import pandas as pd\n",
        "#Now the Pandas package can be referred to as pd instead of pandas.\n"
      ],
      "metadata": {
        "id": "lvDWLo3Y3DHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pandas Series\n",
        "A Pandas Series is like a column in a table.\n",
        "\n",
        "It is a one-dimensional array holding data of any type."
      ],
      "metadata": {
        "id": "WnH_KUV03h7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a simple Pandas Series from a list:\n",
        "import pandas as pd\n",
        "a = [1, 7, 2]\n",
        "myvar = pd.Series(a)\n",
        "print(myvar)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jNWEeQD3s_5",
        "outputId": "ee06a27d-8896-4ebf-eae8-2201375832ac"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    1\n",
            "1    7\n",
            "2    2\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Labels\n",
        "# If nothing else is specified, the values are labeled with their index number. First value has index 0, second value has index 1 etc.\n",
        "\n",
        "# This label can be used to access a specified value.\n",
        "\n",
        "# Example\n",
        "# Return the first value of the Series:\n",
        "\n",
        "print(myvar[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80GkLKxe4FDS",
        "outputId": "e85a9f36-a92f-4e6b-e825-40841cf4faaf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Key/Value Objects as Series\n",
        "# You can also use a key/value object, like a dictionary, when creating a Series.\n",
        "\n",
        "# Example\n",
        "# Create a simple Pandas Series from a dictionary:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "calories = {\"day1\": 420, \"day2\": 380, \"day3\": 390}\n",
        "\n",
        "myvar = pd.Series(calories)\n",
        "\n",
        "print(myvar)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xchGZBem4WHE",
        "outputId": "73a7f4e6-e50e-4d96-bfdf-761e604d3e98"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "day1    420\n",
            "day2    380\n",
            "day3    390\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To select only some of the items in the dictionary, use the index argument and specify only the items you want to include in the Series.\n",
        "\n",
        "# Example\n",
        "# Create a Series using only data from \"day1\" and \"day2\":\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "calories = {\"day1\": 420, \"day2\": 380, \"day3\": 390}\n",
        "\n",
        "myvar = pd.Series(calories, index = [\"day1\", \"day2\"])\n",
        "\n",
        "print(myvar)"
      ],
      "metadata": {
        "id": "O7mKP1SY4ikv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DataFrames\n",
        "Data sets in Pandas are usually multi-dimensional tables, called DataFrames.\n",
        "Series is like a column, a DataFrame is the whole table.\n",
        "\n",
        "A Pandas DataFrame is a 2 dimensional data structure, like a 2 dimensional array, or a table with rows and columns."
      ],
      "metadata": {
        "id": "YRdXxNNi44k0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example\n",
        "# Create a DataFrame from two Series:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "  \"calories\": [420, 380, 390],\n",
        "  \"duration\": [50, 40, 45]\n",
        "}\n",
        "\n",
        "myvar = pd.DataFrame(data)\n",
        "\n",
        "print(myvar)"
      ],
      "metadata": {
        "id": "J-DXCKUG46ID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pandas Read CSV"
      ],
      "metadata": {
        "id": "Wbds_amx6pTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Files Into a DataFrame\n",
        "# If your data sets are stored in a file, Pandas can load them into a DataFrame.\n",
        "\n",
        "# Example\n",
        "# Load a comma separated file (CSV file) into a DataFrame:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "id": "S5AtJG9j5yZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Read CSV files\n",
        "# Example\n",
        "# Load the CSV into a DataFrame:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "print(df.to_string())"
      ],
      "metadata": {
        "id": "DsI3XHXA51Pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If you have a large DataFrame with many rows, Pandas will only return the first 5 rows, and the last 5 rows:\n",
        "\n",
        "# Example\n",
        "# Print the DataFrame without the to_string() method:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "print(df) "
      ],
      "metadata": {
        "id": "qSax6x6w6fa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the JSON file into a DataFrame:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_json('data.json')\n",
        "\n",
        "print(df.to_string())"
      ],
      "metadata": {
        "id": "_Ug6RUNI7rTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Viewing the Data\n",
        "One of the most used method for getting a quick overview of the DataFrame, is the head() method.\n",
        "\n",
        "The head() method returns the headers and a specified number of rows, starting from the top."
      ],
      "metadata": {
        "id": "_ZJLWkAW8DP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get a quick overview by printing the first 10 rows of the DataFrame:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "print(df.head(10))"
      ],
      "metadata": {
        "id": "kpg8iznM8FPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: if the number of rows is not specified, the head() method will return the top 5 rows.\n",
        "\n",
        "# Example\n",
        "# Print the first 5 rows of the DataFrame:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "jrK9lR_28RU8",
        "outputId": "94294c75-bbaf-446a-ef28-dbf3e39aa942"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-31bc8c4c2a3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# There is also a tail() method for viewing the last rows of the DataFrame.\n",
        "\n",
        "# The tail() method returns the headers and a specified number of rows, starting from the bottom.\n",
        "\n",
        "# Example\n",
        "# Print the last 5 rows of the DataFrame:\n",
        "\n",
        "print(df.tail()) "
      ],
      "metadata": {
        "id": "PPVOO45d8gzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Info About the Data\n",
        "# The DataFrames object has a method called info(), that gives you more information about the data set.\n",
        "\n",
        "# Example\n",
        "# Print information about the data:\n",
        "\n",
        "\n",
        "print(df.info()) "
      ],
      "metadata": {
        "id": "PHJ5F5sL9AWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Null Values\n",
        "The info() method also tells us how many Non-Null values there are present in each column, and in our data set it seems like there are 164 of 169 Non-Null values in the \"Calories\" column.\n",
        "\n",
        "Which means that there are 5 rows with no value at all, in the \"Calories\" column, for whatever reason.\n",
        "\n",
        "Empty values, or Null values, can be bad when analyzing data, and you should consider removing rows with empty values. This is a step towards what is called cleaning data"
      ],
      "metadata": {
        "id": "e0VkWRED9XW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cleaning Data\n",
        "Data Cleaning\n",
        "Data cleaning means fixing bad data in your data set.\n",
        "\n",
        "Bad data could be:\n",
        "\n",
        "Empty cells\n",
        "Data in wrong format\n",
        "Wrong data\n",
        "Duplicates"
      ],
      "metadata": {
        "id": "qP2SqeAt9coO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Empty Cells\n",
        "Empty cells can potentially give you a wrong result when you analyze data.\n",
        "\n",
        "Remove Rows\n",
        "One way to deal with empty cells is to remove rows that contain empty cells.\n",
        "\n",
        "This is usually OK, since data sets can be very big, and removing a few rows will not have a big impact on the result."
      ],
      "metadata": {
        "id": "A7iRnKb9-HLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example\n",
        "# Return a new Data Frame with no empty cells:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "new_df = df.dropna()\n",
        "\n",
        "print(new_df.to_string())"
      ],
      "metadata": {
        "id": "kIx3DT3w-IEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: By default, the dropna() method returns a new DataFrame, and will not change the original.\n",
        "\n",
        "# If you want to change the original DataFrame, use the inplace = True argument:\n",
        "\n",
        "# Example\n",
        "# Remove all rows with NULL values:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "df.dropna(inplace = True)\n",
        "\n",
        "print(df.to_string())"
      ],
      "metadata": {
        "id": "b_PQ8gxZ-QBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Replace Empty Values\n",
        "# Another way of dealing with empty cells is to insert a new value instead.\n",
        "\n",
        "# This way you do not have to delete entire rows just because of some empty cells.\n",
        "\n",
        "# The fillna() method allows us to replace empty cells with a value:\n",
        "\n",
        "# Example\n",
        "# Replace NULL values with the number 130:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "df.fillna(130, inplace = True)"
      ],
      "metadata": {
        "id": "ljo6kUgK_DrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace Only For Specified Columns\n",
        "# The example above replaces all empty cells in the whole Data Frame.\n",
        "\n",
        "# To only replace empty values for one column, specify the column name for the DataFrame:\n",
        "\n",
        "# Example\n",
        "# Replace NULL values in the \"Calories\" columns with the number 130:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "df[\"Calories\"].fillna(130, inplace = True)"
      ],
      "metadata": {
        "id": "mV4U-TAO-GTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Replace Using Mean, Median, or Mode"
      ],
      "metadata": {
        "id": "ffTMv-Iz_dhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# A common way to replace empty cells, is to calculate the mean, median or mode value of the column.\n",
        "\n",
        "# Pandas uses the mean() median() and mode() methods to calculate the respective values for a specified column:\n",
        "\n",
        "# Example\n",
        "# Calculate the MEAN, and replace any empty values with it:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "x = df[\"Calories\"].mean()\n",
        "\n",
        "df[\"Calories\"].fillna(x, inplace = True)"
      ],
      "metadata": {
        "id": "BdsdIVwj_ad_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example\n",
        "# Calculate the MEDIAN, and replace any empty values with it:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "x = df[\"Calories\"].median()\n",
        "\n",
        "df[\"Calories\"].fillna(x, inplace = True)"
      ],
      "metadata": {
        "id": "IG1POQhy_p4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example\n",
        "# Calculate the MODE, and replace any empty values with it:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "x = df[\"Calories\"].mode()[0]\n",
        "\n",
        "df[\"Calories\"].fillna(x, inplace = True)"
      ],
      "metadata": {
        "id": "z2O1dFfC_skv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Removing duplicates"
      ],
      "metadata": {
        "id": "AIp1Gqv8Atgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example\n",
        "# Returns True for every row that is a duplicate, othwerwise False:\n",
        "print(df.duplicated())"
      ],
      "metadata": {
        "id": "_ua28SkLAwNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing Duplicates\n",
        "# To remove duplicates, use the drop_duplicates() method.\n",
        "\n",
        "# Example\n",
        "# Remove all duplicates:\n",
        "\n",
        "df.drop_duplicates(inplace = True)\n",
        "\n",
        "#Remember: The (inplace = True) will make sure that the method does NOT return a new DataFrame, but it will remove all duplicates from the original DataFrame."
      ],
      "metadata": {
        "id": "hc0uLZCsA5tI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finding Relationships\n",
        "A great aspect of the Pandas module is the corr() method.\n",
        "\n",
        "The corr() method calculates the relationship between each column in your data set."
      ],
      "metadata": {
        "id": "aoKaakhZBQ6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example\n",
        "# Show the relationship between the columns:\n",
        "\n",
        "df.corr()\n",
        "#Note: The corr() method ignores \"not numeric\" columns."
      ],
      "metadata": {
        "id": "4-ztQtjHBS4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Result Explained\n",
        "The Result of the corr() method is a table with a lot of numbers that represents how well the relationship is between two columns.\n",
        "\n",
        "The number varies from -1 to 1.\n",
        "\n",
        "1 means that there is a 1 to 1 relationship (a perfect correlation), and for this data set, each time a value went up in the first column, the other one went up as well.\n",
        "\n",
        "0.9 is also a good relationship, and if you increase one value, the other will probably increase as well.\n",
        "\n",
        "-0.9 would be just as good relationship as 0.9, but if you increase one value, the other will probably go down.\n",
        "\n",
        "0.2 means NOT a good relationship, meaning that if one value goes up does not mean that the other will.\n",
        "\n",
        "What is a good correlation? It depends on the use, but I think it is safe to say you have to have at least 0.6 (or -0.6) to call it a good correlation.\n",
        "\n",
        "\n",
        "\n",
        "Perfect Correlation:\n",
        "We can see that \"Duration\" and \"Duration\" got the number 1.000000, which makes sense, each column always has a perfect relationship with itself.\n",
        "\n",
        "Good Correlation:\n",
        "\"Duration\" and \"Calories\" got a 0.922721 correlation, which is a very good correlation, and we can predict that the longer you work out, the more calories you burn, and the other way around: if you burned a lot of calories, you probably had a long work out.\n",
        "\n",
        "Bad Correlation:\n",
        "\"Duration\" and \"Maxpulse\" got a 0.009403 correlation, which is a very bad correlation, meaning that we can not predict the max pulse by just looking at the duration of the work out, and vice versa."
      ],
      "metadata": {
        "id": "kgVWhMKZB7r2"
      }
    }
  ]
}